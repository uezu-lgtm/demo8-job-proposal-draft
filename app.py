from __future__ import annotations

import json
import os
import re
from datetime import datetime
from typing import Any

import streamlit as st
from dotenv import load_dotenv
import requests

from llm_clients import ChatMessage, LLMError, build_client, parse_llm_json
from sample_data import (
    SAMPLE_CANDIDATE_1,
    SAMPLE_CANDIDATE_2,
    SAMPLE_JOB_1,
    SAMPLE_JOB_2,
    SAMPLE_PAST_PROPOSALS,
)


load_dotenv()


APP_TITLE = "æ±‚äººææ¡ˆã‚ªãƒšï¼šä¸‹æ›¸ãè‡ªå‹•ç”Ÿæˆï¼ˆæ±‚è·è€…Ã—æ±‚äººï¼‰"


def _now_iso() -> str:
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def _json_preview(obj: Any) -> str:
    return json.dumps(obj, ensure_ascii=False, indent=2)


def _inject_css() -> None:
    st.markdown(
        """
<style>
/* tighten page */
div.block-container { padding-top: 1.2rem; padding-bottom: 2rem; max-width: 1200px; }

.demo-hero {
  border: 1px solid rgba(15, 23, 42, 0.10);
  background: linear-gradient(180deg, rgba(37,99,235,0.08), rgba(255,255,255,0.0));
  border-radius: 16px;
  padding: 16px 16px;
  margin-bottom: 12px;
}
.demo-hero h3 { margin: 0 0 6px 0; font-weight: 700; }
.demo-hero p { margin: 0; color: rgba(15,23,42,0.75); }

.pill {
  display: inline-block;
  padding: 3px 10px;
  border-radius: 999px;
  border: 1px solid rgba(15,23,42,0.12);
  background: rgba(255,255,255,0.9);
  font-size: 12px;
  margin-right: 6px;
}
.pill-strong {
  border-color: rgba(37,99,235,0.35);
  background: rgba(37,99,235,0.10);
}

.hint { color: rgba(15,23,42,0.7); font-size: 13px; }
</style>
        """,
        unsafe_allow_html=True,
    )


def _compact(text: str, limit: int = 60) -> str:
    t = re.sub(r"\s+", " ", (text or "").strip())
    if len(t) <= limit:
        return t
    return t[: limit - 1] + "â€¦"


def _as_markdown(obj: dict[str, Any]) -> str:
    meta = obj.get("metadata", {}) or {}
    lines: list[str] = []
    lines.append("# æ±‚äººææ¡ˆ ä¸‹æ›¸ã")
    lines.append("")
    lines.append(f"- ç”Ÿæˆ: {meta.get('generated_at','-')}")
    if meta.get("provider"):
        lines.append(f"- LLM: {meta.get('provider')}")
    if meta.get("tone"):
        lines.append(f"- ãƒˆãƒ¼ãƒ³: {meta.get('tone')}")
    if meta.get("output_detail"):
        lines.append(f"- è©³ç´°åº¦: {meta.get('output_detail')}")
    if meta.get("match_score") is not None:
        lines.append(f"- ãƒãƒƒãƒåº¦ï¼ˆå‚è€ƒï¼‰: {meta.get('match_score')}")
    lines.append("")

    lines.append("## ææ¡ˆæ–‡ï¼ˆçŸ­æ–‡ï¼‰")
    lines.append("")
    lines.append(obj.get("proposal_short", "") or "")
    lines.append("")

    lines.append("## ææ¡ˆæ–‡ï¼ˆé•·æ–‡ï¼‰")
    lines.append("")
    lines.append(obj.get("proposal_long", "") or "")
    lines.append("")

    lines.append("## æ ¹æ‹ ãƒã‚¤ãƒ³ãƒˆï¼ˆå¼•ç”¨ã¤ãï¼‰")
    lines.append("")
    for i, p in enumerate(obj.get("evidence_points", []) or [], start=1):
        lines.append(f"### {i}. {p.get('title','')}")
        lines.append("")
        lines.append(p.get("why", "") or "")
        lines.append("")
        lines.append("- æ ¹æ‹ ï¼ˆå¼•ç”¨ï¼‰")
        evs = p.get("evidence", []) or []
        if evs:
            for ev in evs:
                quote = (ev.get("quote") or "").strip()
                note = (ev.get("note") or "").strip()
                src = ev.get("source") or "-"
                lines.append(f"  - [{src}] {quote}" + (f"ï¼ˆ{note}ï¼‰" if note else ""))
        else:
            lines.append("  - ï¼ˆãªã—ï¼‰")
        risk = (p.get("risk_or_gap") or "").strip()
        if risk:
            lines.append(f"- æ‡¸å¿µ/ã‚®ãƒ£ãƒƒãƒ—: {risk}")
        qs = p.get("confirm_questions", []) or []
        if qs:
            lines.append("- ç¢ºèªè³ªå•")
            for q in qs:
                lines.append(f"  - {q}")
        lines.append("")

    lines.append("## é€ä»˜å‰ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ")
    lines.append("")
    for c in obj.get("checklist", []) or []:
        lines.append(f"### {c.get('category','')}")
        items = c.get("items", []) or []
        for it in items:
            must = bool(it.get("must", False))
            lines.append(f"- [ ] {'Must' if must else 'Should'}: {it.get('text','')}")
        lines.append("")

    lines.append("## ç¢ºèªè³ªå•ï¼ˆå…¨ä½“ï¼‰")
    lines.append("")
    for q in obj.get("confirm_questions", []) or []:
        lines.append(f"- {q}")
    lines.append("")
    return "\n".join(lines)


def build_prompt(
    *,
    job_text: str,
    candidate_text: str,
    past_examples: str,
    tone: str,
    advisor_role_name: str,
    output_detail: str,
) -> list[ChatMessage]:
    system = f"""ã‚ãªãŸã¯äººæç´¹ä»‹ã®{advisor_role_name}ã§ã™ã€‚ç›®çš„ã¯ã€Œæ±‚äººææ¡ˆã®ä¸‹æ›¸ãã‚’é«˜é€Ÿã«ã€å“è³ªã‚’æƒãˆã¦ä½œã‚‹ã€ã“ã¨ã§ã™ã€‚

å‡ºåŠ›ãƒ«ãƒ¼ãƒ«ï¼ˆæœ€é‡è¦ï¼‰:
- æ—¥æœ¬èªã§å‡ºåŠ›
- è¿”ç­”ã¯ **å¿…ãšJSONã®ã¿**ï¼ˆå‰å¾Œã«èª¬æ˜æ–‡ãƒ»markdownãƒ»ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ç¦æ­¢ï¼‰
- å…¥åŠ›ã«å­˜åœ¨ã—ãªã„æƒ…å ±ã¯æ–­å®šã—ãªã„ã€‚ä¸æ˜ãªå ´åˆã¯ã€Œç¢ºèªè³ªå•ã€ã«å›ã™
- æ ¹æ‹ ãƒã‚¤ãƒ³ãƒˆã«ã¯ã€å¿…ãšã€Œå¼•ç”¨ï¼ˆquoteï¼‰ã€ã‚’æ·»ãˆã‚‹ã€‚å¼•ç”¨ã¯åŸæ–‡ã‹ã‚‰ã®æŠœãå‡ºã—ã§ã€é•·ãã¦ã‚‚60æ–‡å­—
- å¼•ç”¨ãŒå–ã‚Œãªã„å ´åˆã¯ quote ã‚’ç©ºæ–‡å­—ã«ã—ã€note ã«ã€Œå¼•ç”¨ç®‡æ‰€ä¸æ˜ã€ã¨æ›¸ã

ã‚ãªãŸã®ä»•äº‹:
1) ãƒãƒƒãƒç†ç”±ï¼ˆæ ¹æ‹ ï¼‰ã‚’æŠ½å‡ºï¼ˆè‰¯ã„ç‚¹/æ‡¸å¿µ/è¦ç¢ºèªã‚’åˆ†é›¢ï¼‰
2) ææ¡ˆæ–‡ï¼ˆçŸ­æ–‡/é•·æ–‡ï¼‰ã‚’ç”Ÿæˆï¼ˆãƒˆãƒ¼ãƒ³: {tone}ã€è©³ç´°åº¦: {output_detail}ï¼‰
3) é€ä»˜æ™‚ã®æ³¨æ„ç‚¹ï¼ˆæ¡ä»¶/ç¢ºèªäº‹é …ï¼‰ã‚’ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆåŒ–ï¼ˆMust/Shouldï¼‰
4) ç¢ºèªè³ªå•ã‚’å…·ä½“çš„ã«æç¤ºï¼ˆé€ä»˜å‰ãƒ»é¢è«‡ã§èãï¼‰

å‡ºåŠ›JSONã‚¹ã‚­ãƒ¼ãƒ:
{{
  "metadata": {{
    "generated_at": "{_now_iso()}",
    "tone": "{tone}",
    "output_detail": "{output_detail}",
    "match_score": 0.0
  }},
  "evidence_points": [
    {{
      "title": "string",
      "why": "string",
      "evidence": [
        {{
          "source": "job|candidate|past",
          "quote": "string",
          "note": "string"
        }}
      ],
      "risk_or_gap": "string",
      "confirm_questions": ["string"],
      "confidence": "high|medium|low"
    }}
  ],
  "proposal_short": "string",
  "proposal_long": "string",
  "checklist": [
    {{
      "category": "string",
      "items": [
        {{
          "text": "string",
          "must": true
        }}
      ]
    }}
  ],
  "confirm_questions": ["string"]
}}
"""

    user = f"""ä»¥ä¸‹ã®å…¥åŠ›ã‚’ã‚‚ã¨ã«ã€ã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ã¦JSONã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã€æ±‚äººç¥¨ã€‘
{job_text}

ã€æ±‚è·è€…ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã€‘
{candidate_text}

ã€éå»ææ¡ˆä¾‹ï¼ˆã‚¹ã‚¿ã‚¤ãƒ«å‚è€ƒã€‚å†…å®¹ã®äº‹å®Ÿã¯å‚ç…§ã—ãªã„ï¼‰ã€‘
{past_examples}
"""

    return [ChatMessage(role="system", content=system), ChatMessage(role="user", content=user)]


def validate_result(obj: dict[str, Any]) -> list[str]:
    errs: list[str] = []
    for k in ["metadata", "evidence_points", "proposal_short", "proposal_long", "checklist", "confirm_questions"]:
        if k not in obj:
            errs.append(f"ã‚­ãƒ¼æ¬ è½: {k}")
    if "evidence_points" in obj and not isinstance(obj["evidence_points"], list):
        errs.append("evidence_points ã¯é…åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
    if "checklist" in obj and not isinstance(obj["checklist"], list):
        errs.append("checklist ã¯é…åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
    if "confirm_questions" in obj and not isinstance(obj["confirm_questions"], list):
        errs.append("confirm_questions ã¯é…åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
    return errs


def try_ollama_tags(base_url: str) -> tuple[bool, str]:
    try:
        base = base_url.rstrip("/")

        # 1) Native endpoint
        url = base + "/api/tags"
        r = requests.get(url, timeout=8)
        ct = (r.headers.get("Content-Type") or "").lower()
        if "application/json" not in ct:
            snippet = (r.text or "")[:120].replace("\n", " ")
            return (
                False,
                f"JSONã§ã¯ãªã„å¿œç­”ã§ã™ï¼ˆstatus={r.status_code}, content-type={ct}ï¼‰ã€‚"
                f" BASE_URLãŒOllamaã§ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹: http://localhost:11434 / snippet: {snippet}",
            )
        if r.status_code == 404:
            # 2) OpenAI-compatible endpoint
            url2 = base + "/v1/models"
            r2 = requests.get(url2, timeout=8)
            ct2 = (r2.headers.get("Content-Type") or "").lower()
            if "application/json" not in ct2:
                snippet2 = (r2.text or "")[:120].replace("\n", " ")
                return (
                    False,
                    f"JSONã§ã¯ãªã„å¿œç­”ã§ã™ï¼ˆstatus={r2.status_code}, content-type={ct2}ï¼‰ã€‚"
                    f" BASE_URLãŒOllamaã§ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹: http://localhost:11434 / snippet: {snippet2}",
                )
            r2.raise_for_status()
            data2 = r2.json()
            models2 = [m.get("id", "") for m in (data2.get("data") or [])]
            models2 = [m for m in models2 if m]
            if models2:
                return True, " / ".join(models2[:8]) + (" â€¦" if len(models2) > 8 else "")
            return True, "ï¼ˆãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã¯ç©ºã§ã—ãŸï¼‰"

        r.raise_for_status()
        data = r.json()
        models = [m.get("name", "") for m in (data.get("models") or [])]
        models = [m for m in models if m]
        if models:
            return True, " / ".join(models[:8]) + (" â€¦" if len(models) > 8 else "")
        return True, "ï¼ˆãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã¯ç©ºã§ã—ãŸï¼‰"
    except Exception as e:
        return False, str(e)


def repair_json_with_llm(client, raw: str, schema_hint: str) -> str:
    messages = [
        ChatMessage(
            role="system",
            content="ã‚ãªãŸã¯JSONæ•´å½¢å™¨ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã€æŒ‡ç¤ºã•ã‚ŒãŸJSONã‚¹ã‚­ãƒ¼ãƒã«æ²¿ã†ã€ŒJSONã®ã¿ã€ã«æ•´å½¢ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚ä½™è¨ˆãªæ–‡ç« ã¯ç¦æ­¢ã€‚",
        ),
        ChatMessage(
            role="user",
            content=f"ã“ã®å‡ºåŠ›ã‚’JSONã«æ•´å½¢ã—ã¦ãã ã•ã„ã€‚ã‚¹ã‚­ãƒ¼ãƒè¦ä»¶: {schema_hint}\n\n---\n{raw}\n---",
        ),
    ]
    return client.complete(messages, temperature=0.0)


def render_result(obj: dict[str, Any]) -> None:
    meta = obj.get("metadata", {})
    top = st.columns([1, 1, 2], vertical_alignment="center")
    with top[0]:
        st.metric("ãƒãƒƒãƒåº¦ï¼ˆå‚è€ƒï¼‰", f"{meta.get('match_score','-')}")
    with top[1]:
        st.metric("æ ¹æ‹ ãƒã‚¤ãƒ³ãƒˆæ•°", f"{len(obj.get('evidence_points', []) or [])}")
    with top[2]:
        st.caption(
            f"ç”Ÿæˆ: {meta.get('generated_at', '-') } / LLM={meta.get('provider','-')} / tone={meta.get('tone','-')} / detail={meta.get('output_detail','-')}"
        )

    tab1, tab2, tab3, tab4 = st.tabs(["æ ¹æ‹ ãƒã‚¤ãƒ³ãƒˆ", "ææ¡ˆæ–‡ï¼ˆçŸ­æ–‡ï¼‰", "ææ¡ˆæ–‡ï¼ˆé•·æ–‡ï¼‰", "ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ/ç¢ºèªè³ªå•"])

    with tab1:
        pts = obj.get("evidence_points", []) or []
        if not pts:
            st.info("æ ¹æ‹ ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…¥åŠ›ã‚’å¢—ã‚„ã™ã‹ã€éå»ææ¡ˆä¾‹ã‚’å…¥ã‚Œã¦å†ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        for i, p in enumerate(pts, start=1):
            title = p.get("title", f"ãƒã‚¤ãƒ³ãƒˆ{i}")
            conf = p.get("confidence", "-")
            with st.expander(f"{i}. {title}  / confidence: {conf}", expanded=i <= 2):
                st.markdown("**ãªãœãƒãƒƒãƒã™ã‚‹ã‹**")
                st.write(p.get("why", ""))
                st.markdown("**æ ¹æ‹ ï¼ˆå¼•ç”¨ï¼‰**")
                evs = p.get("evidence", []) or []
                if evs:
                    for ev in evs:
                        st.write(f"- **{ev.get('source','-')}**: ã€Œ{_compact(ev.get('quote',''))}ã€ {('â€” ' + ev.get('note','')) if ev.get('note') else ''}")
                else:
                    st.write("- ï¼ˆãªã—ï¼‰")
                st.markdown("**æ‡¸å¿µ/ã‚®ãƒ£ãƒƒãƒ—**")
                st.write(p.get("risk_or_gap", ""))
                st.markdown("**ã“ã®ãƒã‚¤ãƒ³ãƒˆã«é–¢ã™ã‚‹ç¢ºèªè³ªå•**")
                qs = p.get("confirm_questions", []) or []
                if qs:
                    for q in qs:
                        st.write(f"- {q}")
                else:
                    st.write("- ï¼ˆãªã—ï¼‰")

    with tab2:
        st.text_area("çŸ­æ–‡ï¼ˆã‚³ãƒ”ãƒšç”¨ï¼‰", value=obj.get("proposal_short", ""), height=180)

    with tab3:
        st.text_area("é•·æ–‡ï¼ˆé€ä»˜æ–‡æ¡ˆï¼‰", value=obj.get("proposal_long", ""), height=360)

    with tab4:
        st.markdown("**é€ä»˜å‰ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**")
        checklist = obj.get("checklist", []) or []
        if not checklist:
            st.write("ï¼ˆãªã—ï¼‰")
        for c in checklist:
            cat = c.get("category", "ã‚«ãƒ†ã‚´ãƒª")
            st.markdown(f"**{cat}**")
            items = c.get("items", []) or []
            for it in items:
                must = bool(it.get("must", False))
                label = f"{'Must' if must else 'Should'}: {it.get('text','')}"
                st.checkbox(label, value=False, key=f"chk::{cat}::{label}")

        st.divider()
        st.markdown("**ç¢ºèªè³ªå•ï¼ˆå…¨ä½“ï¼‰**")
        for q in obj.get("confirm_questions", []) or []:
            st.write(f"- {q}")

        with st.expander("JSONï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰"):
            st.code(_json_preview(obj))


def main() -> None:
    st.set_page_config(page_title=APP_TITLE, layout="wide", page_icon="ğŸ“")
    _inject_css()
    st.title(APP_TITLE)
    st.markdown(
        """
<div class="demo-hero">
  <h3>â€œææ¡ˆãŒä¸€ç¬ã§å‡ºã‚‹â€ä½“é¨“</h3>
  <p>æ±‚äººç¥¨Ã—æ±‚è·è€…ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‹ã‚‰ã€ææ¡ˆæ–‡æ¡ˆï¼ˆçŸ­æ–‡/é•·æ–‡ï¼‰ãƒ»æ ¹æ‹ ï¼ˆå¼•ç”¨ï¼‰ãƒ»é€ä»˜å‰ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚</p>
</div>
        """,
        unsafe_allow_html=True,
    )

    with st.sidebar:
        st.subheader("è¨­å®š")
        provider = st.selectbox("LLMãƒ—ãƒ­ãƒã‚¤ãƒ€", ["ollama", "mock"], index=0)
        tone = st.selectbox("ãƒˆãƒ¼ãƒ³", ["ä¸å¯§", "ãƒ•ãƒ©ãƒ³ã‚¯ï¼ˆä¸å¯§å¯„ã‚Šï¼‰", "ç¡¬ã‚ï¼ˆãƒ“ã‚¸ãƒã‚¹ï¼‰"], index=0)
        output_detail = st.selectbox("è©³ç´°åº¦", ["çŸ­ã‚", "æ¨™æº–", "ä¸å¯§ã‚"], index=1)
        advisor_role_name = st.text_input("å½¹å‰²å‘¼ç§°ï¼ˆè¡¨ç¤º/ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ï¼‰", value="ã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼")
        temperature = st.slider("æ¸©åº¦ï¼ˆãƒ–ãƒ¬ï¼‰", 0.0, 1.0, 0.2, 0.05)

        st.divider()
        st.caption("Ollamaï¼ˆä»»æ„ï¼‰")
        st.session_state.setdefault("ollama_base_url", os.environ.get("OLLAMA_BASE_URL", "http://localhost:11434"))
        st.session_state.setdefault("ollama_model", os.environ.get("OLLAMA_MODEL", "llama3.1"))

        reset_cols = st.columns([1, 1])
        if reset_cols[0].button("11434ã«æˆ»ã™", use_container_width=True):
            st.session_state["ollama_base_url"] = "http://localhost:11434"
        if reset_cols[1].button("ã‚¢ãƒ—ãƒªURLã‚’å…¥ã‚Œã¦ã—ã¾ã£ãŸ", use_container_width=True):
            st.session_state["ollama_base_url"] = "http://localhost:11434"

        base_url = st.text_input(
            "OLLAMA_BASE_URL",
            key="ollama_base_url",
            help="Ollamaã®URLï¼ˆé€šå¸¸: http://localhost:11434ï¼‰ã€‚â€»ã‚¢ãƒ—ãƒªã®URLï¼ˆä¾‹: http://localhost:8502ï¼‰ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
        )
        model = st.text_input("OLLAMA_MODEL", key="ollama_model")
        if ":8502" in base_url or base_url.rstrip("/").endswith(":8502"):
            st.warning("OLLAMA_BASE_URL ãŒã‚¢ãƒ—ãƒª(8502)ã‚’æŒ‡ã—ã¦ã„ã¾ã™ã€‚é€šå¸¸ã¯ http://localhost:11434 ã§ã™ã€‚")
        if st.button("Ollamaæ¥ç¶šãƒã‚§ãƒƒã‚¯"):
            ok, msg = try_ollama_tags(base_url)
            if ok:
                st.success(f"æ¥ç¶šOKã€‚models: {msg}")
            else:
                st.error(f"æ¥ç¶šNG: {msg}")

        st.divider()
        st.caption("ç’°å¢ƒå¤‰æ•°ï¼ˆãƒ¡ãƒ¢ï¼‰")
        st.code(
            "OLLAMA_BASE_URL / OLLAMA_MODEL",
            language="text",
        )

    col_in, col_out = st.columns([1, 1], gap="large")

    with col_in:
        st.subheader("å…¥åŠ›")
        b1, b2, b3, b4 = st.columns(4)
        if b1.button("ã‚µãƒ³ãƒ—ãƒ«æŠ•å…¥ï¼ˆ1ï¼‰"):
            st.session_state["job_text"] = SAMPLE_JOB_1
            st.session_state["candidate_text"] = SAMPLE_CANDIDATE_1
            st.session_state["past_examples"] = SAMPLE_PAST_PROPOSALS
        if b2.button("ã‚µãƒ³ãƒ—ãƒ«æŠ•å…¥ï¼ˆ2ï¼‰"):
            st.session_state["job_text"] = SAMPLE_JOB_2
            st.session_state["candidate_text"] = SAMPLE_CANDIDATE_2
            st.session_state["past_examples"] = SAMPLE_PAST_PROPOSALS
        if b3.button("éå»ææ¡ˆä¾‹ã ã‘æŠ•å…¥"):
            st.session_state["past_examples"] = SAMPLE_PAST_PROPOSALS
        if b4.button("ã‚¯ãƒªã‚¢"):
            st.session_state["job_text"] = ""
            st.session_state["candidate_text"] = ""
            st.session_state["past_examples"] = ""
            st.session_state.pop("last_raw", None)
            st.session_state.pop("last_obj", None)

        st.markdown(
            f"""<span class="pill pill-strong">å…¥åŠ›</span>
<span class="pill">æ±‚äººç¥¨</span><span class="pill">ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«</span><span class="pill">éå»ææ¡ˆä¾‹(ä»»æ„)</span>""",
            unsafe_allow_html=True,
        )
        job_text = st.text_area("æ±‚äººç¥¨ãƒ†ã‚­ã‚¹ãƒˆ", key="job_text", height=250, placeholder="ã“ã“ã«æ±‚äººç¥¨ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è²¼ã‚Šä»˜ã‘")
        candidate_text = st.text_area(
            "æ±‚è·è€…ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«",
            key="candidate_text",
            height=250,
            placeholder="ã“ã“ã«æ±‚è·è€…ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è²¼ã‚Šä»˜ã‘",
        )
        past_examples = st.text_area(
            "éå»ææ¡ˆä¾‹ï¼ˆä»»æ„ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«å‚è€ƒï¼‰",
            key="past_examples",
            height=160,
            placeholder="è‰¯ã„ææ¡ˆã®ä¾‹ï¼ˆåŒ¿åï¼‰ã‚’è²¼ã‚Šä»˜ã‘ã€‚ç„¡ãã¦ã‚‚å‹•ãã¾ã™ã€‚",
        )

        disabled = not (job_text.strip() and candidate_text.strip())
        generate = st.button("ä¸‹æ›¸ãã‚’ç”Ÿæˆ", type="primary", disabled=disabled, use_container_width=True)

        if disabled:
            st.info("æ±‚äººç¥¨ã¨æ±‚è·è€…ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’å…¥ã‚Œã‚‹ã¨ç”Ÿæˆã§ãã¾ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«æŠ•å…¥ã‚‚ä½¿ãˆã¾ã™ã€‚")

    with col_out:
        st.subheader("å‡ºåŠ›")
        if generate:
            try:
                # apply sidebar inputs to env for this session
                os.environ["OLLAMA_BASE_URL"] = base_url
                os.environ["OLLAMA_MODEL"] = model
                client = build_client(provider)
                st.session_state["last_provider_name"] = getattr(client, "name", provider)
                messages = build_prompt(
                    job_text=job_text,
                    candidate_text=candidate_text,
                    past_examples=past_examples,
                    tone=tone,
                    advisor_role_name=advisor_role_name,
                    output_detail=output_detail,
                )
                with st.spinner(f"ç”Ÿæˆä¸­â€¦ï¼ˆ{st.session_state['last_provider_name']}ï¼‰"):
                    raw = client.complete(messages, temperature=float(temperature))
                st.session_state["last_raw"] = raw
                schema_hint = "metadata/evidence_points/proposal_short/proposal_long/checklist/confirm_questions ã‚’å«ã‚€"
                try:
                    obj = parse_llm_json(raw)
                except LLMError:
                    # Best-effort repair once (Ollama output sometimes contains extra text)
                    repaired = repair_json_with_llm(client, raw, schema_hint)
                    st.session_state["last_raw"] = repaired
                    obj = parse_llm_json(repaired)
                # add some metadata we know
                obj.setdefault("metadata", {})
                obj["metadata"].setdefault("generated_at", _now_iso())
                obj["metadata"]["provider"] = st.session_state["last_provider_name"]
                errs = validate_result(obj)
                if errs:
                    st.error("JSONã¯èª­ã‚ã¾ã—ãŸãŒã€æœŸå¾…ã‚¹ã‚­ãƒ¼ãƒã¨å·®åˆ†ãŒã‚ã‚Šã¾ã™ã€‚")
                    for e in errs:
                        st.write(f"- {e}")
                    with st.expander("ç”Ÿå‡ºåŠ›"):
                        st.code(raw)
                    with st.expander("JSONï¼ˆè§£æå¾Œï¼‰"):
                        st.code(_json_preview(obj))
                else:
                    st.session_state["last_obj"] = obj
                    render_result(obj)

                    md = _as_markdown(obj)
                    st.divider()
                    dl = st.columns([1, 1, 2])
                    with dl[0]:
                        st.download_button(
                            "ææ¡ˆä¸€å¼ï¼ˆMarkdownï¼‰ã‚’DL",
                            data=md.encode("utf-8"),
                            file_name="proposal_draft.md",
                            mime="text/markdown",
                            use_container_width=True,
                        )
                    with dl[1]:
                        st.download_button(
                            "JSONã‚’DL",
                            data=_json_preview(obj).encode("utf-8"),
                            file_name="proposal_result.json",
                            mime="application/json",
                            use_container_width=True,
                        )
                    with dl[2]:
                        st.caption("DLã—ãŸMarkdownã‚’ãã®ã¾ã¾ç¤¾å†…å…±æœ‰ãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«å›ã›ã¾ã™ã€‚")
            except LLMError as e:
                st.error(str(e))
                raw = st.session_state.get("last_raw")
                if raw:
                    with st.expander("ç›´è¿‘ã®ç”Ÿå‡ºåŠ›"):
                        st.code(raw)
            except Exception as e:  # pragma: no cover
                st.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
                raw = st.session_state.get("last_raw")
                if raw:
                    with st.expander("ç›´è¿‘ã®ç”Ÿå‡ºåŠ›"):
                        st.code(raw)
        else:
            if "last_obj" in st.session_state:
                render_result(st.session_state["last_obj"])
            else:
                st.info("ã¾ã ç”Ÿæˆã—ã¦ã„ã¾ã›ã‚“ã€‚å·¦ã§å…¥åŠ›ã—ã¦ã€Œä¸‹æ›¸ãã‚’ç”Ÿæˆã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

    st.divider()
    with st.expander("é‹ç”¨ä¸Šã®æ³¨æ„ï¼ˆãƒ‡ãƒ¢è¨­è¨ˆï¼‰"):
        st.write(
            "- å‡ºåŠ›ã¯ä¸‹æ›¸ãã§ã™ã€‚é€ä»˜å‰ã«ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã¨æ ¹æ‹ å¼•ç”¨ã‚’å¿…ãšç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
            "- å…¥åŠ›ã«ãªã„æƒ…å ±ã¯æ–­å®šã›ãšã€ç¢ºèªè³ªå•ã¨ã—ã¦æç¤ºã™ã‚‹è¨­è¨ˆã§ã™ã€‚\n"
            "- éå»ææ¡ˆä¾‹ã¯â€œæ–‡ä½“/æ§‹æˆâ€ã®å‚è€ƒã¨ã—ã¦ã®ã¿ä½¿ç”¨ã—ã€äº‹å®Ÿæƒ…å ±ã¯å‚ç…§ã—ã¾ã›ã‚“ã€‚"
        )


if __name__ == "__main__":
    main()

